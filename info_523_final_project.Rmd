---
title: "INFO523 Final Project"
author: "Amber Converse, Kai Shuen Neo, Iris Sum"
date: "2024-05-05"
output: pdf_document
---

## Introduction (Amber Converse)

Using data from a collection of police shootings in the United States, we performed an exploration of the statistics of shootings using a data mining methods for data pre-processing and analysis. We reached a hypothesis that there is an association between race and the weapon used. While a Chi-Squared analysis showed a correlation between race and the weapon used, the results of Cramer's V on that correlation lead us to accept the null hypothesis, showing that there is no correlation between race and the weapon used.

## Data and Methods (Amber Converse)

The data used was a collection of 8,720 police shootings that happened in the US. Each shooting record had 19 attributes: 1) id, 2) data, 3) threat_type, 4) flee_status, 5) armed_with, 6) city, 7) county, 8) state, 9) latitude, 10) longitude, 11) location_precision, 12) name, 13) age, 14) gender, 15) race, 16) race_source, 17) was_mental_illness_related, 18) body_camera, 19) agency_ids. Attributes were organized into 3 data types: numeric, nominal, and binary. County values were missing in over 50% of cases, but were able to imputed using the US Cities Data CSV to reduce the missing number of values of 7.6%. For our analysis, location was standarized using the state attribute as it reflected regional differences with no data loss. The attributes gender, threat_type, flee_status, armed_with, age, and race were selected as important attributes for analysis and rows with these attributes missing were removed as imputation was impossible for these attributes.

First, data exploration was performed using summary statistics to define the distribution of the data for selected attributes. Then, data pre-processing was performed by analyzing missing values for attributes and performing a Pearson's correlation coefficient analysis and Chi-Squared correlation test. Next, frequent itemsets were mined using the Apriori algorithm and association rules were generated from those itemsets. Then, a Random Forest model and decision tree were generated to predict race using the selected attributes. Cluster analysis was performed using two methods, PAM and OPTICS. Finally, the data was analyzed using outlier detection to search for global (both univariate and multivariate) and contextual outliers.

## Results and Discussions (Kai Shuen Neo)

This section would be divided into 6 parts based on the 6 assignments that we had completed over the semester upon analyzing the police shooting data set.

Assignment 1 was about knowing our data, where we employed descriptive and exploratory statistics to understand our data set. To explore our data set, we looked into attributes, with a focus on gender, and with gender as a base, its various characteristics and features - age, race (White, Black, Hispanic, Native American, Asian, and Other), weapons. 

Our analysis from Assignment 1 have shown that out of a total of 8672 victims (having victims with invalid gender value filtered out), 95.6% were males while the remaining 4.39% were females. From our bar chart, it was majorly obvious that the gender male made up the majority of the distribution. Based on the following gender distribution, we further analysed the age feature (by removing victims with NA age value) by differentiating victims via their age groups, namely 1) '10 or below', 2) '11 to 20', 3) '21 to 30', 4) '31 to 40', 5) '41 to 50', 6) '51 to 60', 7) '61 to 70', 8) 'Above 70'. Visualizations from our table, box plot, statistic summary and bar chart (figure 1) have shown that the average age for both male and female victims lie in the '41 to 50' age group. As for the race feature (victims with multiple races had all their races accounted for in our counts), based on our bar plot for both male and female victims, 'White', 'Black' and 'Hispanic' races were commonly targeted. Finally for the weapon feature (victims with multiple weapons had all their weapons accounted for in our counts), based on our table and bar plot visualizations, 'Gun' and 'Knife' were the most common weapons used for both male and female victims. Therefore, key findings here was that males had a higher tendency of being victimized in fatal police shootings, with most of them being of 'White' race, and having 'Gun' as their weapon of choice. However, there is a need to note that there were missing data in the data set and interpretation needs to be contexual here to give deeper meaning, thus these were just findings that we made of the sample collected from the records of the data set, not conclusive of the entire population.

```{r echo=FALSE, fig.width=8, fig.height=3.5, fig.align="center", message=FALSE, fig.cap = "Bar Chart of the Distribution of Age for Male and Female Victims"}
library(ggplot2)
library(gridExtra)
library(dplyr)
library(tidyr)

df <- read.csv("fatal-police-shootings-data.csv")

df <- df[(df$gender == "male" | df$gender == "female"), ]

age_df <- df[!is.na(df$age), c("gender", "age")]

## filter each gender data
male_df <- age_df |>
  filter(gender == "male") |>
  group_by(age) |>
  count(name = "count")

female_df <- age_df |>
  filter(gender == "female") |>
  group_by(age) |>
  count(name = "count")

p_male <- ggplot(male_df, aes(x = age, y = count)) + 
  geom_col(
    color = "deepskyblue4",
    fill = "lightskyblue"
  ) + 
  labs(
    x = "Age",
    y = "Number of male victims",
  ) +
  theme_classic()

p_female <- ggplot(female_df, aes(x = age, y = count)) + 
  geom_col(
    color = "deeppink3",
    fill = "pink"
  ) + 
  labs(
    x = "Age",
    y = "Number of female victims",
  ) +
  theme_classic()

grid.arrange(p_male, p_female, ncol=2)
```

Assignment 2 was about data processing, where we examined missing data and evaluated the different approaches to deal with missing data, by removing data or by imputing missing data. Thereafter, we tested for correlation and independence between categorical variables and between continuous variables to detect relationships between variables and even to identify redundant attributes in the data set. 

Our analysis from Assignment 2 have shown that out of the 19 attributes, 14 attributes had missing values, with the attribute 'county' having 55.68% of missing data. Other attributes like 'name', 'age', 'threat_type',  'flee_status', 'armed_with', 'gender', 'race', 'race_source' had <20% of missing data. On the ways to handle such missing data, it came down to the conclusion that it would need to depend on how we understand the attribute's context, its source and what we were focused on analyzing the attribute for. If a small percentage of data were missing, it might be possible for us to remove such data. However, if it was the contrary, it would be best if we selected another attribute to bank our analysis upon. As for imputing missing data, it's possible if they were non-sensitive.  However, if they were for contextual and specific purposes, imputing data is not a good solution as there is a high chance that doing so would lead to inaccurate analysis. To look for correlations between variables, we used the Pearson's correlation coefficient analysis, where we focused on numeric attributes (age, date, latitude, longitude) from our data set. We tested for correlations between age, date and location of shooting and found that there was no significant correlation between them. To further confirm this, we plotted a Scarlet plot against each attribute. Similarly, no linear correlations were observed. This suggests that in each area, the victims in random age were shot in random years. To further test for correlation, we did the Chi-squared analysis on weapon type and race of the victim. According to the Chi-squared test results, weapon type is correlated with race. As shown in tables 1 and 2, black victims were more likely to be unarmed or have a gun, but less likely to have a replica weapon. White victims were more likely to have a replica, but less likely to be unarmed or have a gun. However, upon testing this correlation with Cramer's V, we got a value of 0.07, which suggests the correlation is not strong. Thus, we reject our hypothesis.

```{r, echo=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(scales)
library(rcompanion)

police.data <- read.csv("fatal-police-shootings-data.csv")

processed_police.data <- police.data %>%
  select(armed_with, race) %>%
  separate_rows(armed_with, sep=";") %>% 
  mutate(armed_with = case_when(
    armed_with == "" ~ "Unlisted",
    armed_with == "blunt_object" ~ "Melee Weapon",
    armed_with == "gun" ~ "Gun",
    armed_with == "knife" ~ "Melee Weapon",
    armed_with == "other" ~ "Other",
    armed_with == "replica" ~ "Replica",
    armed_with == "unarmed" ~ "Unarmed",
    armed_with == "undetermined" ~ "Unknown",
    armed_with == "unknown" ~ "Unknown",
    armed_with == "vehicle" ~ "Vehicle"
  )) %>%
  filter(armed_with != "Unlisted") %>% 
  separate_rows(race, sep=";") %>% 
  mutate(race = case_when(
    race == "" ~ "Unlisted",
    race == "A" ~ "Asian",
    race == "B" ~ "Black",
    race == "H" ~ "Hispanic",
    race == "N" ~ "None",
    race == "O" ~ "Other",
    race == "W" ~ "White"
  ))

freq_table_armed_cam <- processed_police.data %>% 
  group_by(armed_with, race) %>%
  count() %>%
  ungroup() %>%
  spread(armed_with, n)

chisq_analysis <- chisq.test(processed_police.data$armed_with,
                             processed_police.data$race,
                             simulate.p.value = TRUE)

observed = data.frame(chisq_analysis$observed)
expected = data.frame(chisq_analysis$expected)

observed_black <- observed[observed$processed_police.data.race
                           == "Black", ]
observed_white <- observed[observed$processed_police.data.race
                           == "White", ]

diff_black <- label_percent()(((
  observed_black$Freq -   
  expected$Black) /
  expected$Black))

diff_white <- label_percent()(((
  observed_white$Freq -   
  expected$White) /
  expected$White))

compare_df <- data.frame(observed_black$Var1, expected$Black, 
                         observed_black$Freq, diff_black,
                         expected$White, observed_white$Freq, 
                         diff_white)

compare_black <- 
  data.frame(observed_black$Var1, expected$Black, observed_black$Freq)
compare_black$diff <- label_percent()(((
  compare_black$observed_black.Freq -   
  compare_black$expected.Black) /
  compare_black$expected.Black))

compare_white <- 
  data.frame(observed_white$Var1, expected$White, observed_white$Freq)
compare_white$diff <- label_percent()(((
  compare_white$observed_white.Freq -   
  compare_white$expected.White) /
  compare_white$expected.White))

kable(compare_df, col.names=c("Weapon", "Expected (Black)", "Actual (Black)", "Difference (Black)", "Expected (White)", "Actual (White)", "Difference (White)"), caption="Expected Frequency vs. Actual Frequency for Black and White Victims")

# kable(compare_black, col.names=c("Weapon", "Expected Frequency", "Actual Frequency", "Difference"), caption="Expected Frequency vs. Actual Frequency in Cases where the Race of the Victim was Black")

# kable(compare_white, col.names=c("Weapon", "Expected Frequency", "Actual Frequency", "Difference"), caption="Expected Frequency vs. Actual Frequency in Cases where the Race of the Victim was White")
```

Assignment 3 was about association rule mining, whereby we mined frequent item sets and frequent association rules using an appropriate mining method and also selected good support and confidence thresholds. With that, we applied good quality measures to select the best rules. 

Our analysis from Assignment 3 required us to first perform the required data pre-processing discussed in the data section. With the pre-processed data, we used the Apriori algorithm to mine the 5 longest frequent item sets for male and female victims. The item set with the highest support (0.086) and count (781) for male victims turned out to be [gender=male, race=H, race_source=not_available, was_mental_illness_related=False, body_camera=False]. As for female victims, the item set with the highest support (0.086) and count (36) turned out to be [flee_status=, gender=female, was_mental_illness_related=False, body_camera=False]. In addition, we mined the 5 strong association rules, measured with Kulc scores and Imbalance Ratio scores. It was interesting that for the 5 rules that we had mined for female victims, they all had over 96% confidence level, indicating that they were strong rules. The strongest rule would be involving team A police officer when a female victim has some kind of weapon visible to the officers on the scene. The Kulc scores were within the range of 0.59 to 0.67, not high enough to reflect a significant positive correlation. The rules are imbalanced since they had an imbalance ratio of over 0.59. As for male victims, the 5 rules that we had mined all had over 98% confidence level, indicating that they were strong rules. The strongest rule would be that the male victim was armed with a firearm or gun when he fired a weapon. 4 out of 5 rules had a Kulc score of over 0.7, indicating a positive correlation. These rules were less imbalanced as compared to the ones for female victims as they had imbalance ratio within 0.51 to 0.64.

Assignment 4 was about classification, where we looked into 2 classification models, Decision Tree and Random Forest model. 

Our analysis from Assignment 4 required us to first select attributes to predict the races for Random Forest. Identifying information and agency_ids were removed due to high cardinality and lack of usefulness for prediction. Date had high cardinality, it was removed to create 2 new attributes, month and year, which had reasonable cardinality for a Random Forest model. Rows with multiple values for an attribute were separated out. Any category that was not likely to help with the predictions were also filtered away. The data were then converted to the correct data types for Random Forest. The Random Forest model was then constructed with data split in train (80%) and test (20%) sets. No class weights were included as they had negligible effects on performance. It had an overall accuracy of 56%, with race 'White' having precision 0.59 and recall 0.78, race 'Black' having precision 0.54 and recall 0.42, race 'Hispanic' having precision 0.45 and recall 0.30, race 'Asian' having precision 0.00 and recall 0.00,. race 'Native American' and 'Other' both having precision NaN and recall 0.00. We then evaluated the important attributes using the attribute importance plot for random forest model - having age and region as the most important attributes, followed by was_mental_illness_related, and finally gender and month. This made sense conceptually as gender did not really predict race and it is unlikely that shootings in different months affected different races differently. This model further leads us to reject our hypothesis as the attribute armed_with was not important for predicting race. Thereafter, we trained a Decision Tree to predict races using only the age attribute, and used the test data to evaluate the Decision Tree's performance in terms of precision and recall. Here, race 'White' had a precision 0.57 and recall 0.89, race 'Black' had precision 0.44 and recall 0.30, race 'Asian', 'Hispanic', 'Native American', 'Other' had precision NaN and recall 0.00. Upon comparing the Decision Tree and Random Forest model, we think that the Random Forest model actually performed better than the Decision Tree, as seen from the lesser number of NaN precision values and lesser number of 0.00 recall values tabulated across the races. Another insight that we gained upon examining race distributions across different age groups was that 44% of race 'White' were of ages < 26, 20% of race 'White' were of ages between ages 26 and 40, 36% of race 'White' had ages > 40. On the other hand, 100% of race 'Black' had ages < 26. The races 'Asian', 'Hispanic', 'Native American' and 'Other' were labelled as unused due to their precision value of NaN and recall value of 0.00. As such, each node in the Decision Tree is either 'White' or 'Black'.

Assignment 5 was about clustering analysis, where we compared 2 clustering methods, PAM and OPTICS. 

Our analysis from Assignment 5 required us to first select attributes for clustering analysis, and we selected continuous attributes (date, latitude, longitude, age, city population, city population density) for the use of Hopkins Statistic in our analysis, to test for clustering. On assessing clustering tendency, as the data points were not randomly distributed, thus there was clustering tendency. Thereafter, we conducted clustering analysis using PAM and found that there was a total of 4 distinct clusters. Finally, upon conducting clustering analysis using OPTICS with a reachability plot of eps = 0.199, we gathered a total of 6 distinct clusters. Upon comparing the clustering results from PAM and OPTICS, we gathered that in terms of their similarities, both PAM & OPTICS had one big cluster and other smaller clusters, and that the dominating cluster in both PAM & OPTICS share similar attribute characteristic - which is that a majority of the observations were white male victims armed with gun. As for their differences, the number of clusters in PAM was 4 while for OPTICS it was 6. OPTICS generated clusters with more pure observations' class in each attribute whereas PAM's clusters contained a mixture of attributes. For PAM's clustering results, the clusters had a dominating class in each attributes instead of solely having one class, whereas many observations were identified as noise for OPTICS.

```{r echo=FALSE, fig.width=3.5, fig.height=3.5, message=FALSE, warning=FALSE, fig.cap = "Boxplot of the Distribution of Age for Each Gender"}
library(dplyr)
library(ggplot2)

data <- read.csv("fatal-police-shootings-data.csv")

data %>% ggplot() +
  geom_boxplot(aes(x = gender, y = age))
```


Lastly, Assignment 6 was about outlier detection, where we detected 3 outlier types namely 1) global outlier, 2) contextual outlier, 3) collective outlier.

Our analysis from Assignment 6 have shown that in terms of global outlier, a victim with very large age (significantly older than the majority of the victims) may considered to be a global outlier. Similarly, a victim of a different race (from the typical race options defined for police shooting data) may also be considered a global outlier. For univariate global outliers, in terms of the nominal attributes (e.g. race, armed_with), for typically defined race options, a sample outlier observations would have "B,H" as an outlier. As for typically defined armed_with options - "gun", "unarmed", "replica", "other", "knife", "blunt_object", "vehicle", a sample outlier observations would have "other, blunt_object, knife" as an outlier. As for numeric attributes, we may observe the outliers with a box plot, such that for points that lie beyond the whiskers, they can be casted as outliers. As for contextual outliers, based on our box plot (figure 1), our context is that ages > 70 years are considered outliers. And as observed from our boxplot, it is true that outliers appear around 75 years for both male and females. Finally for collective outliers, an example of collective outliers would be a cluster of victims that as a collective had a mean of 70-years-old with low variance between them. This differs significantly from the overall distribution of age across the country. For multivariate global outliers, a key finding was that Hawaii was pointed out as an outlier. But it should not be so just because of its global positioning.

# References

“United States Cities Database.” Simplemaps, simplemaps.com/data/us-cities. Accessed 5 May 2024.